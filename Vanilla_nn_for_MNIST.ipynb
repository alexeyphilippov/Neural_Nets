{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksejfilippov/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс one-hot encoder'а для MNIST\n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        self.transform_mapping = np.zeros((10,10))\n",
    "        for i in range(self.transform_mapping.shape[0]):\n",
    "            self.transform_mapping[i][i] = 1.0\n",
    "    def transform(self, y):\n",
    "        return self.transform_mapping[int(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(X_test, net, fname=\"my_submission.csv\"):\n",
    "    with open(fname,'w') as fout:\n",
    "        fout.write('Id,Category')\n",
    "        for i in range(X_test.shape[0]):\n",
    "            y_h = net.forward(X_test[i])\n",
    "            y = np.argmax(y_h)\n",
    "            fout.write(\"\\n{},{}\".format(i, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# внимание, тут Y_test в обычном формате(не onehot)\n",
    "def compute_acc(X_test, Y_test, net):\n",
    "    acc = 0.0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        y_h = net.forward(X_test[i])\n",
    "        y = np.argmax(y_h)\n",
    "        if(y == Y_test[i]):\n",
    "            acc += 1.0\n",
    "    return acc / Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = None\n",
    "test_data = None\n",
    "encoder = OneHotEncoder()\n",
    "with open('data_train.pickle','rb') as fin:\n",
    "    train_data = pickle.load(fin)\n",
    "with open('data_test_no_labels.pickle','rb') as fin:\n",
    "    test_data = pickle.load(fin)\n",
    "    \n",
    "X = train_data['data']\n",
    "Y = train_data['target']\n",
    "Y_oh = np.array(list(map(lambda x : encoder.transform(x), Y)))\n",
    "\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X = (X - mean) / (std + 0.0001)\n",
    "X_test_fin = (X - mean) / (std + 0.0001)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, Yf_train, Yf_test = train_test_split(X, Y_oh, Y, test_size=0.33, stratify=Y)\n",
    "\n",
    "X_test_fin = test_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35175, 784)\n",
      "(17500, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test_fin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение слоев сети\n",
    "# class Dense:\n",
    "class Dense:\n",
    "    def __init__(self, in_size, out_size, rlambda = 0.001):\n",
    "        self.W = np.random.normal(scale=1, size=(out_size, in_size)) * np.sqrt(2/(out_size + in_size))\n",
    "        self.b = np.zeros(out_size)\n",
    "        self.rlambda = rlambda\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x # запоминаем для обратного прохода\n",
    "        return np.dot(self.W, x) + self.b\n",
    "    \n",
    "    def get_reg_loss(self):\n",
    "        return 0.5 * self.rlambda * (np.linalg.norm(self.W, ord='fro') ** 2)\n",
    "    \n",
    "    def backward(self, dz, lr=0.001):\n",
    "        # вычисляем градиенты по параметрам (запоминаем их для отладки)\n",
    "        self.dW = np.outer(dz, self.x)\n",
    "        self.db = dz\n",
    "        # вычисляем производную по входу\n",
    "        self.dx = np.matmul(dz, self.W) \n",
    "        # рассчитываем градиенты от регуляризатора\n",
    "        if(self.rlambda != 0):\n",
    "            self.dW += self.rlambda * self.W\n",
    "        # обновляем веса\n",
    "        self.W = self.W - lr * self.dW\n",
    "        self.db = self.db - lr * self.db\n",
    "        # возвращаем dx для продолжения алгоритма\n",
    "        return self.dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    \n",
    "    def forward(self, y_true, y_hat):\n",
    "        self.y_true = y_true\n",
    "        self.y_hat = y_hat\n",
    "        return -np.sum(y_true * np.log(y_hat))\n",
    "    \n",
    "    def backward(self, dz, lr=0.00001):\n",
    "        return dz * -1. * self.y_true / self.y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def backward(self, dz, lr=0.1):\n",
    "        dz[self.x < 0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        exps = np.exp(x)\n",
    "        return exps / np.sum(exps)\n",
    "    \n",
    "    def backward(self, dz, lr=0.001):\n",
    "        z = self.forward(self.x)\n",
    "        self.lp = (np.eye(z.shape[0], z.shape[0]) - z).T\n",
    "        self.lp2 = z * self.lp\n",
    "        return np.dot(dz, self.lp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p = 0.5):\n",
    "        self.p = p\n",
    "        self.train = True\n",
    "    \n",
    "    def set_train(self, train = True):\n",
    "        self.train = train\n",
    "        \n",
    "    def set_p(self, p):\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if not self.train:\n",
    "            self.mask = np.ones(*x.shape)\n",
    "            return x\n",
    "        self.mask = ( np.random.rand(*x.shape) > self.p ) / (1.0 - self.p)\n",
    "        return x * self.mask\n",
    "        \n",
    "    def backward(self, dz, lr=0.001):\n",
    "        return dz * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNet1:\n",
    "    def set_rlambda(self, rlambda = 0.0):\n",
    "        self.rlambda = rlambda\n",
    "    \n",
    "    def __init__(self, rlambda = self.rlambda):\n",
    "        self.d1 = Dense(784, 220, self.rlambda)\n",
    "        self.m1 = Max()\n",
    "        self.dr2 = Dropout(0.3)\n",
    "        self.d2 = Dense(220, 10, self.rlambda)\n",
    "        self.s = Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        net = self.d1.forward(x)\n",
    "        net = self.m1.forward(net)\n",
    "        net = self.dr2.forward(net)\n",
    "        net = self.d2.forward(net)\n",
    "        net = self.s.forward(net)\n",
    "        return net\n",
    "    \n",
    "    def backward(self, dz, lr = 0.001):\n",
    "        dz = self.s.backward(dz, lr)\n",
    "        dz = self.d2.backward(dz, lr)\n",
    "        dz = self.dr2.backward(dz, lr)\n",
    "        dz = self.m1.backward(dz, lr)\n",
    "        dz = self.d1.backward(dz, lr)\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iter loss. Train : 0.4989127013568638 . Test : 0.25729520452182647\n",
      "1 iter loss. Train : 0.2786643247603829 . Test : 0.21587876741247225\n",
      "2 iter loss. Train : 0.23086243764287062 . Test : 0.20131416478584063\n",
      "3 iter loss. Train : 0.2048049960013973 . Test : 0.1786169034575989\n",
      "4 iter loss. Train : 0.1806705114191323 . Test : 0.17272360803267162\n",
      "5 iter loss. Train : 0.1668810978627045 . Test : 0.16570971121680214\n",
      "6 iter loss. Train : 0.15293247058570178 . Test : 0.156955436798562\n",
      "7 iter loss. Train : 0.14102029562373308 . Test : 0.15643656727253735\n",
      "8 iter loss. Train : 0.13097681946957151 . Test : 0.15120017913538392\n",
      "9 iter loss. Train : 0.12226140458455788 . Test : 0.1472998294466532\n",
      "10 iter loss. Train : 0.12015112953460912 . Test : 0.14299017357912683\n",
      "11 iter loss. Train : 0.11188702004574025 . Test : 0.14260842746919997\n",
      "12 iter loss. Train : 0.10941669559636516 . Test : 0.13921793075556058\n",
      "13 iter loss. Train : 0.10748764871588566 . Test : 0.14075211670534163\n",
      "14 iter loss. Train : 0.106258830831712 . Test : 0.13707959156118718\n",
      "15 iter loss. Train : 0.10092223388766196 . Test : 0.13456792553373464\n",
      "16 iter loss. Train : 0.09522634907493642 . Test : 0.13314604010749834\n",
      "17 iter loss. Train : 0.09284333976628963 . Test : 0.13257101552197256\n",
      "18 iter loss. Train : 0.08898947382968772 . Test : 0.13031233381003368\n",
      "19 iter loss. Train : 0.08742826251673735 . Test : 0.129190362016245\n",
      "20 iter loss. Train : 0.08482960155183988 . Test : 0.12981796060859557\n",
      "21 iter loss. Train : 0.08521700994042047 . Test : 0.12735531918101314\n",
      "22 iter loss. Train : 0.082210750889309 . Test : 0.12550611935155878\n",
      "23 iter loss. Train : 0.08441758835624406 . Test : 0.12229979372883064\n",
      "24 iter loss. Train : 0.07868980437987458 . Test : 0.12419500957679135\n",
      "25 iter loss. Train : 0.07762247367684576 . Test : 0.12263142691484967\n",
      "26 iter loss. Train : 0.07919928489015908 . Test : 0.11996021599297967\n",
      "27 iter loss. Train : 0.07705251203557645 . Test : 0.11688855530514457\n",
      "28 iter loss. Train : 0.07159872136462676 . Test : 0.11853698452598188\n",
      "29 iter loss. Train : 0.07120058027345055 . Test : 0.11815669982500761\n",
      "30 iter loss. Train : 0.07167504490894591 . Test : 0.11952320037942163\n",
      "31 iter loss. Train : 0.0699236263354371 . Test : 0.11685569500398867\n",
      "32 iter loss. Train : 0.07210486533522122 . Test : 0.11650992862248949\n",
      "33 iter loss. Train : 0.0743517797243881 . Test : 0.11483901440305486\n",
      "34 iter loss. Train : 0.07363369040296792 . Test : 0.11540483230477233\n",
      "35 iter loss. Train : 0.07087037274338157 . Test : 0.11470030437287938\n",
      "36 iter loss. Train : 0.07140581067801142 . Test : 0.11371343349007804\n",
      "37 iter loss. Train : 0.0711470142781444 . Test : 0.11351950826028886\n",
      "38 iter loss. Train : 0.06642954926110603 . Test : 0.11280859699202825\n",
      "39 iter loss. Train : 0.06893040041624232 . Test : 0.11675067397289693\n",
      "40 iter loss. Train : 0.07028329634774311 . Test : 0.11293861554365105\n",
      "41 iter loss. Train : 0.07271643017631571 . Test : 0.11428133875793173\n",
      "42 iter loss. Train : 0.07001745340688685 . Test : 0.1112210878480594\n",
      "43 iter loss. Train : 0.06988067938291584 . Test : 0.10975582509594917\n",
      "44 iter loss. Train : 0.06790364627367367 . Test : 0.11041840594273616\n",
      "45 iter loss. Train : 0.06652655944241559 . Test : 0.10896677278489472\n",
      "46 iter loss. Train : 0.0695589159118933 . Test : 0.1103201344372096\n",
      "47 iter loss. Train : 0.06820781886181884 . Test : 0.1120039387357107\n",
      "48 iter loss. Train : 0.07124073051756208 . Test : 0.11082955665495432\n",
      "49 iter loss. Train : 0.07183924394976433 . Test : 0.11217157404218298\n",
      "50 iter loss. Train : 0.06620682565736845 . Test : 0.11141145251505748\n",
      "51 iter loss. Train : 0.07119922236714205 . Test : 0.1131990085910668\n",
      "52 iter loss. Train : 0.06386888005245842 . Test : 0.11022804386999754\n",
      "53 iter loss. Train : 0.062342183528521125 . Test : 0.11013450413945511\n",
      "54 iter loss. Train : 0.06308585078050125 . Test : 0.1104794163331685\n",
      "55 iter loss. Train : 0.06513029109950023 . Test : 0.11184817280965341\n",
      "56 iter loss. Train : 0.06393883670022338 . Test : 0.11116359758281033\n",
      "57 iter loss. Train : 0.06231060152519913 . Test : 0.11178142991097113\n",
      "58 iter loss. Train : 0.06574201388597606 . Test : 0.11534676774893368\n",
      "59 iter loss. Train : 0.06752931659865907 . Test : 0.1121158374535744\n",
      "60 iter loss. Train : 0.06638400293313086 . Test : 0.11257717284735327\n",
      "61 iter loss. Train : 0.06197911621254227 . Test : 0.11426910459021267\n",
      "62 iter loss. Train : 0.06607911749719135 . Test : 0.11030712226137478\n",
      "63 iter loss. Train : 0.06379315631464826 . Test : 0.11169011500258912\n",
      "64 iter loss. Train : 0.06457831910303355 . Test : 0.11282521611702297\n",
      "65 iter loss. Train : 0.06455719396886526 . Test : 0.11058982464474035\n",
      "66 iter loss. Train : 0.060529842150178446 . Test : 0.11378782271504544\n",
      "67 iter loss. Train : 0.06098400892555391 . Test : 0.11857261027635267\n",
      "68 iter loss. Train : 0.06531391734655888 . Test : 0.11543261321399169\n",
      "69 iter loss. Train : 0.05981404848233388 . Test : 0.11367721817258757\n",
      "70 iter loss. Train : 0.0588991953404927 . Test : 0.11385952905214031\n",
      "71 iter loss. Train : 0.06186047626825605 . Test : 0.11055690585744941\n",
      "72 iter loss. Train : 0.057760917184801565 . Test : 0.11024277724950318\n",
      "73 iter loss. Train : 0.06412676675783036 . Test : 0.10834660235239493\n",
      "74 iter loss. Train : 0.06422065163735842 . Test : 0.11144340782082045\n",
      "75 iter loss. Train : 0.06134561068681687 . Test : 0.11170457936525524\n",
      "76 iter loss. Train : 0.0630760923493314 . Test : 0.11103496481788644\n",
      "77 iter loss. Train : 0.06522904559233131 . Test : 0.10955910774701384\n",
      "78 iter loss. Train : 0.060888448925834886 . Test : 0.11413787533529328\n",
      "79 iter loss. Train : 0.05853227984906896 . Test : 0.1110711497441878\n",
      "80 iter loss. Train : 0.061208301672391094 . Test : 0.11063899285682381\n",
      "81 iter loss. Train : 0.06326274023695616 . Test : 0.10919315904297557\n",
      "82 iter loss. Train : 0.06212121529922048 . Test : 0.10990772631515978\n",
      "83 iter loss. Train : 0.06143790250610565 . Test : 0.11071450677390966\n",
      "84 iter loss. Train : 0.06236801606299132 . Test : 0.1077119722833031\n",
      "85 iter loss. Train : 0.06065266504879856 . Test : 0.10673389982634023\n",
      "86 iter loss. Train : 0.060108826697859316 . Test : 0.11096951035466202\n",
      "87 iter loss. Train : 0.061512660980179865 . Test : 0.10636307966961266\n",
      "88 iter loss. Train : 0.05905705835560019 . Test : 0.10670755750974943\n",
      "89 iter loss. Train : 0.058848454270868114 . Test : 0.11082815065403889\n",
      "90 iter loss. Train : 0.0605796613677988 . Test : 0.11018210378373122\n",
      "91 iter loss. Train : 0.06032251274382963 . Test : 0.10667686673836334\n",
      "92 iter loss. Train : 0.06028064922065804 . Test : 0.10747710328329767\n",
      "93 iter loss. Train : 0.061609564675400824 . Test : 0.10519794125877935\n",
      "94 iter loss. Train : 0.05950921802168391 . Test : 0.10744198680132833\n",
      "95 iter loss. Train : 0.05806909673734484 . Test : 0.10819058148642018\n",
      "96 iter loss. Train : 0.05905980068753776 . Test : 0.10665870799743338\n",
      "97 iter loss. Train : 0.05946924637240423 . Test : 0.1041712439775567\n",
      "98 iter loss. Train : 0.05901222132916144 . Test : 0.1079785692610589\n",
      "99 iter loss. Train : 0.06061514354345413 . Test : 0.10569088728574635\n"
     ]
    }
   ],
   "source": [
    "net = MnistNet1(0.001)\n",
    "loss = CrossEntropy()\n",
    "net.dr2.set_train(True)\n",
    "net.dr2.set_p(0.5)\n",
    "lr = 0.001\n",
    "L_train = []\n",
    "L_test = []\n",
    "accuracy_test = []\n",
    "accuracy_train = []\n",
    "for iter in range(100):\n",
    "    L_acc = 0.\n",
    "    sh = list(range(X_train.shape[0])) # больше рандома богу рандома\n",
    "    np.random.shuffle(sh)\n",
    "    for i in range(X_train.shape[0]):\n",
    "        x = X_train[sh[i]]\n",
    "        y = Y_train[sh[i]]\n",
    "        y_h = net.forward(x)\n",
    "        L = loss.forward(y, y_h) #+ net.get_reg_loss()\n",
    "        L_acc += L \n",
    "        dz = loss.backward(1, lr)\n",
    "        dz = net.backward(dz, lr)\n",
    "    L_acc /= Y_train.shape[0]\n",
    "    L_train.append(L_acc)\n",
    "    net.dr2.set_train(False)\n",
    "    L_e_acc = 0.\n",
    "    for i in range(X_test.shape[0]):\n",
    "        x = X_test[i]\n",
    "        y = Y_test[i]\n",
    "        y_h = net.forward(x)\n",
    "        L = loss.forward(y, y_h) #+ net.get_reg_loss()\n",
    "        L_e_acc += L\n",
    "    L_e_acc /= Y_test.shape[0]\n",
    "    L_test.append(L_e_acc)\n",
    "    net.dr2.set_train(True)\n",
    "    print(\"{} iter loss. Train : {} . Test : {}\".format(iter, L_acc, L_e_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583838383838383"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_acc(X_test, Yf_test, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10b901e80>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L_train, label='train')\n",
    "plt.plot(L_test, label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksejfilippov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# формируем сабмишшен и заливаем его на kaggle\n",
    "net.dr2.set_train(False)\n",
    "\n",
    "make_submission(X_test_fin, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
